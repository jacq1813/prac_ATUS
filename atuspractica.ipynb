{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9542333,"sourceType":"datasetVersion","datasetId":5813083}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":15.953882,"end_time":"2024-10-03T20:47:19.861533","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-03T20:47:03.907651","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.968768,"end_time":"2024-10-03T20:47:07.971755","exception":false,"start_time":"2024-10-03T20:47:07.002987","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-04T00:26:19.870247Z","iopub.execute_input":"2024-10-04T00:26:19.870676Z","iopub.status.idle":"2024-10-04T00:26:20.357810Z","shell.execute_reply.started":"2024-10-04T00:26:19.870630Z","shell.execute_reply":"2024-10-04T00:26:20.355999Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/atus-practica/.DS_Store\n/kaggle/input/atus-practica/atus_anual_csv/leeme_faq.txt\n/kaggle/input/atus-practica/atus_anual_csv/.DS_Store\n/kaggle/input/atus-practica/atus_anual_csv/metadatos/metadatos_atus_anual_1997_2023.txt\n/kaggle/input/atus-practica/atus_anual_csv/diccionario_de_datos/diccionario_de_datos_atus_anual_1997_2023.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_hora.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_municipio.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_dia.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_entidad.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_minuto.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_periodo_mes.csv\n/kaggle/input/atus-practica/atus_anual_csv/catalogos/tc_edad.csv\n/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2021.csv\n/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2022.csv\n/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/.DS_Store\n/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2023.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preparación y limpieza del Dataset\n\n\n- Realizamos la carga de los 3 datasets necesarios para la practica y posteriormente los concatenamos (juntamos), ademas antes de eso se verifica la correcta carga de los datasets y se encontró que el de 2021 no era correcto, ya que habia un error de formato csv.","metadata":{}},{"cell_type":"code","source":"\n# Lee el archivo y limpia las líneas con comas finales\nwith open('/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2021.csv', 'r') as file:\n    lines = file.readlines()\n\n# Elimina comas adicionales al final de cada línea\ncleaned_lines = [line.rstrip(',\\n') + '\\n' for line in lines]\n\n# Escribir las líneas limpiadas a un archivo temporal\nwith open('/kaggle/working/atus_anual_2021_cleaned.csv', 'w') as cleaned_file:\n    cleaned_file.writelines(cleaned_lines)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T02:55:21.348541Z","iopub.execute_input":"2024-10-04T02:55:21.349606Z","iopub.status.idle":"2024-10-04T02:55:22.349380Z","shell.execute_reply.started":"2024-10-04T02:55:21.349551Z","shell.execute_reply":"2024-10-04T02:55:22.347984Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## 1. Cargue en un dataframe los datos de los accidentes de los ultimos 3 años","metadata":{}},{"cell_type":"code","source":"# Ahora cargamos el archivo limpio en pandas\ndf1 = pd.read_csv('/kaggle/working/atus_anual_2021_cleaned.csv')\n\n# cargar en un dataframe los datos de atus_anual_2021.csv, atus_anual_2022.csv, atus_anual_2023.csv\ndf2 = pd.read_csv('/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2022.csv')\ndf3 = pd.read_csv('/kaggle/input/atus-practica/atus_anual_csv/conjunto_de_datos/atus_anual_2023.csv')\n\ndf = pd.concat([df1, df2, df3])\n\nprint(df)","metadata":{},"execution_count":null,"outputs":[]}]}